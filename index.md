# Books
# Biased data
- A Caliskan, JJ Bryson, and A Narayanan (2017) [Semantics Derived Automatically from Language Corpora Contain Human-Like Biases](https://arxiv.org/abs/1608.07187), Science, 356 (6334): 183–86.
# Criteria of Algorithmic Fairness 
- J Kleinberg, J Ludwig, S Mullainathan, and A Rambachan (2018), [Algorithmic Fairness](https://www.cs.cornell.edu/home/kleinber/aer18-fairness.pdf) (2018)
  > (Including race among predictors improves both accuracy and equity (greater share of minority students admitted). 
    Based on college admission data. Paper argues against excluding race as a predictor for the purpose of achieving better algorithmic fairness.) 
# Impossibility results
- A Chouldechova (2017), [Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments](https://arxiv.org/pdf/1703.00056.pdf), Big Data, 5(2): 153–63
- J Kleinberg, S Mullainathan, and M Raghavan (201), [Inherent Trade-Offs in the Fair Determination of Risk Scores](https://arxiv.org/abs/1609.05807) Proceedings of the 8th Conference on Innovation
in Theoretical Computer Science, 43:1–43:23
